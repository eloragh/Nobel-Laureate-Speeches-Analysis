{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nobel Peace Prize Speech Analysis\n",
    "\n",
    "## This notebook walks through how I updated my initial analysis and the improvements I made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import re\n",
    "import collections as col\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project Revisted - 2022/nobelspeeches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project Revisted - 2022/ns_speech_analysis_redo.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project%20Revisted%20-%202022/ns_speech_analysis_redo.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#define the path where the speech files are found\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project%20Revisted%20-%202022/ns_speech_analysis_redo.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m path \u001b[39m=\u001b[39m Path\u001b[39m.\u001b[39mcwd()\u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnobelspeeches\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project%20Revisted%20-%202022/ns_speech_analysis_redo.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nobel_speeches \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project%20Revisted%20-%202022/ns_speech_analysis_redo.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#join the path with the files to find the appropriate file when looking for it\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project%20Revisted%20-%202022/ns_speech_analysis_redo.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m files \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m([os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m nobel_speeches \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/eloraghespie/Documents/GitHub/nobel_speeches_freq_analysis-1/Project Revisted - 2022/nobelspeeches'"
     ]
    }
   ],
   "source": [
    "#define the path where the speech files are found\n",
    "path = Path/ \"nobelspeeches\"\n",
    "nobel_speeches = os.listdir(path)\n",
    "\n",
    "#join the path with the files to find the appropriate file when looking for it\n",
    "files = sorted([os.path.join(path, file) for file in nobel_speeches if file.endswith('.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The stopwords provided by the NLTK corpus are a list of the most common words in each language.\n",
    "#### For English - \"the\", \"it\", \"a\", \"and\", \"when\", etc.\n",
    "#### These words have almost no contributing value to the analysis, so we use stopwords to weed those out.\n",
    "#### I added a few pieces of punctuation to the list of stopwords to weed those out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "stops.update([\"–\",\"…\",\"*\", \" \", \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of tokenizing the words, I used a for loop to iterate through them and pull them out of each file into a list.\n",
    "\n",
    "#### I also used regex to tackle some of the more challenging issues within the data so that the final result was as clean as possible.\n",
    "\n",
    "#### The collections module is useful for quickly forming dictionaries out of iterable datatypes and then sorting the dictionaries by their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    file1 = open(file, encoding = \"utf8\")\n",
    "    file2 = file1.read()\n",
    "    file3 = re.sub(\"\\b\\W?(\\w*)\\W?\\b\", r\"/1\", file2)\n",
    "    file4 = re.sub(r\"[\\b?\\(\\n*)](\\w*)[\\(\\n*)\\b?]\", r\" \\1\", file3)\n",
    "    file4 = re.sub(r\"\\\\n*\", \" \", file3)\n",
    "    file5 = re.sub(r\"(,|;|:|\\.|)?(\\w*)(,|;|:|\\.|)?\", r\"\\2\", file4)\n",
    "    file5.replace(\"\\n\", \" \")\n",
    "    lst = file5.lower().split(\" \")\n",
    "\n",
    "    for word in lst:\n",
    "        if word.startswith(\"\\'\"):\n",
    "            pass\n",
    "        elif word not in stops:\n",
    "            vocab_list.append(word)\n",
    "\n",
    "most_frequent_words = col.Counter(vocab_list).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of a list with a word and the occurence value, I used a dictionary and took advantage of the key:value strengths.\n",
    "\n",
    "#### This data is far cleaner and was organized in a much shorter time with far fewer lines of code.\n",
    "\n",
    "#### Uncomment the last line to see the most frequently used words of the last 29 Nobel Laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most_frequent_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
